use indoc::indoc;
use std::fs;
use std::io::{self, Write};
use std::path::Path;

use crate::lexer::Lexer;
use crate::token::TokenType;

const CROW_IMAGE: &str = indoc! {
    "
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿⡟⠋⢻⣷⣄⡀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣤⣾⣿⣷⣿⣿⣿⣿⣿⣶⣾⣿⣿⠿⠿⠿⠶⠄⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠉⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡟⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⡟⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⣿⣿⣿⣿⣿⣿⠟⠻⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⣿⣿⣿⣿⣿⣿⣆⣤⠿⢶⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⢰⣿⣿⣿⣿⣿⣿⣿⣿⡀⠀⠀⠀⠑⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠸⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠙⠛⠋⠉⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
  "
};

// ───── Helper: tokenize a file and dump tokens to stdout ──────────────────────
pub fn read_and_tokenize_file(file_path: &Path) -> io::Result<()> {
    let src = fs::read_to_string(file_path)?;
    let mut lexer = Lexer::new(src, file_path.into());
    let tokens = lexer.scan_tokens();

    for tok in tokens {
        println!(
            "Token Type: {:<15}, TokenLiteral: {}",
            tok.token_type, tok.literal
        );
    }

    Ok(())
}

// ───── Interactive REPL (lexes each user line) ───────────────────────────────
pub fn run_repl() {
    let mut line_input = String::new();

    println!("{CROW_IMAGE}");
    println!("Welcome to the Carrion REPL!");
    println!("Type 'quit' or 'exit' to leave.\n");

    loop {
        print!(">>> ");
        io::stdout().flush().unwrap();

        line_input.clear();
        if io::stdin().read_line(&mut line_input).is_err() {
            eprintln!("Input error; try again.");
            continue;
        }
        let input = line_input.trim();
        if matches!(input, "quit" | "exit") {
            println!("Farewell. May the All-Father bless your travels!");
            break;
        }

        // Tokenize the user’s input line
        let mut lexer = Lexer::new(input.to_owned(), "<stdin>".into());
        for tok in lexer.scan_tokens() {
            if tok.token_type != TokenType::Eof {
                println!("{:<15}  {}", tok.token_type, tok.literal);
            }
        }
    }
}
